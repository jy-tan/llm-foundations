# Scaling

Research on how model performance changes with increased compute, data, and parameters. Scaling laws help practitioners make informed decisions about resource allocation, while work on emergent abilities explores capabilities that appear only at sufficient scale. These papers guide the economics and strategy of large model development.

## Scaling laws

<table>
  <tr>
    <th>Title</th>
    <th>Authors</th>
    <th>Year</th>
  </tr>
  <tr>
    <td><a href="https://arxiv.org/abs/2001.08361">Scaling Laws for Neural Language Models</a></td>
    <td>Kaplan et al.</td>
    <td>2020</td>
  </tr>
  <tr>
    <td><a href="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models</a></td>
    <td>Hoffmann et al.</td>
    <td>2022</td>
  </tr>
</table>

## Emergent abilities

<table>
  <tr>
    <th>Title</th>
    <th>Authors</th>
    <th>Year</th>
  </tr>
  <tr>
    <td><a href="https://arxiv.org/abs/2206.07682">Emergent Abilities of Large Language Models</a></td>
    <td>Wei et al.</td>
    <td>2022</td>
  </tr>
  <tr>
    <td><a href="https://arxiv.org/abs/2304.15004">Are Emergent Abilities of Large Language Models a Mirage?</a></td>
    <td>Schaeffer et al.</td>
    <td>2023</td>
  </tr>
</table>
